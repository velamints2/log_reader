#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½æ—¥å¿—è¯Šæ–­Agent
- ç†è§£æ¯ä¸ªlogæ–‡ä»¶çš„ç”¨é€”
- æ ¹æ®FAEæè¿°çš„é—®é¢˜æ™ºèƒ½é€‰æ‹©ç›¸å…³æ—¥å¿—
- å¤šè½®åˆ†æï¼Œæ·±åº¦è¯Šæ–­
"""

import json
import os
import re
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from collections import defaultdict
import requests
from config import (
    DEEPSEEK_API_KEY, DEEPSEEK_BASE_URL, DEEPSEEK_MODEL, 
    MAX_TOKENS, TEMPERATURE, REQUEST_TIMEOUT, LOG_DIRECTORY
)

# æ—¥å¿—æ–‡ä»¶çŸ¥è¯†åº“ - æè¿°æ¯ä¸ªæ—¥å¿—æ–‡ä»¶è®°å½•ä»€ä¹ˆå†…å®¹
LOG_KNOWLEDGE_BASE = {
    # ===== æ ¸å¿ƒé©±åŠ¨å±‚ =====
    "ikitbot_driver.log": {
        "category": "æ ¸å¿ƒé©±åŠ¨",
        "description": "æœºå™¨äººåº•å±‚é©±åŠ¨æ—¥å¿—ï¼Œè®°å½•IMUã€ç”µæ± ã€è¶…å£°æ³¢ã€ç”µæœºç­‰ç¡¬ä»¶çŠ¶æ€",
        "keywords": ["imu", "battery", "ultrasonic", "motor", "driver", "collision", "bump"],
        "problems": ["ç”µæœºæ•…éšœ", "ä¼ æ„Ÿå™¨å¼‚å¸¸", "ç¢°æ’", "ç”µæ± é—®é¢˜", "IMUå¼‚å¸¸", "è¶…å£°æ³¢æ•…éšœ", "ç¡¬ä»¶ç¦»çº¿"],
        "importance": "high"
    },
    "odometry_node.log": {
        "category": "æ ¸å¿ƒé©±åŠ¨",
        "description": "é‡Œç¨‹è®¡èŠ‚ç‚¹æ—¥å¿—ï¼Œè®°å½•æœºå™¨äººä½ç½®ã€é€Ÿåº¦ã€å§¿æ€ç­‰è¿åŠ¨æ•°æ®",
        "keywords": ["odom", "pose", "velocity", "position", "orientation", "wheel"],
        "problems": ["é‡Œç¨‹è®¡æ¼‚ç§»", "ä½ç½®ä¸å‡†", "é€Ÿåº¦å¼‚å¸¸", "è½®å­æ‰“æ»‘"],
        "importance": "high"
    },
    
    # ===== å¯¼èˆªå±‚ =====
    "navigation_move_base.log": {
        "category": "å¯¼èˆª",
        "description": "å¯¼èˆªæ ¸å¿ƒæ—¥å¿—ï¼Œè®°å½•è·¯å¾„è§„åˆ’ã€ä»£ä»·åœ°å›¾ã€å¯¼èˆªçŠ¶æ€",
        "keywords": ["navigation", "costmap", "path", "goal", "plan", "obstacle", "slam"],
        "problems": ["å¯¼èˆªå¤±è´¥", "è·¯å¾„è§„åˆ’å¤±è´¥", "é¿éšœå¼‚å¸¸", "ç›®æ ‡ä¸å¯è¾¾", "ä»£ä»·åœ°å›¾é—®é¢˜"],
        "importance": "high"
    },
    "navigation_hsm_flex.log": {
        "category": "å¯¼èˆª",
        "description": "å¯¼èˆªçŠ¶æ€æœºæ—¥å¿—ï¼Œè®°å½•å¯¼èˆªä»»åŠ¡çŠ¶æ€è½¬æ¢å’Œè·¨æ¥¼å±‚å¯¼èˆª",
        "keywords": ["navigation", "state", "floor", "elevator", "trans_vel"],
        "problems": ["å¯¼èˆªçŠ¶æ€å¼‚å¸¸", "è·¨æ¥¼å±‚é—®é¢˜", "é€Ÿåº¦æ§åˆ¶å¼‚å¸¸"],
        "importance": "medium"
    },
    "cartographer_node.INFO": {
        "category": "å®šä½å»ºå›¾",
        "description": "Cartographer SLAMæ—¥å¿—(INFOçº§åˆ«)ï¼Œè®°å½•å»ºå›¾å’Œå®šä½ä¿¡æ¯",
        "keywords": ["cartographer", "slam", "map", "localization", "submap", "scan"],
        "problems": ["å®šä½ä¸¢å¤±", "å»ºå›¾å¤±è´¥", "SLAMå¼‚å¸¸"],
        "importance": "high"
    },
    "cartographer_node.WARNING": {
        "category": "å®šä½å»ºå›¾",
        "description": "Cartographer SLAMæ—¥å¿—(WARNINGçº§åˆ«)ï¼Œè®°å½•å»ºå›¾å’Œå®šä½è­¦å‘Š",
        "keywords": ["cartographer", "slam", "warning"],
        "problems": ["å®šä½æ¼‚ç§»", "å»ºå›¾è´¨é‡é—®é¢˜"],
        "importance": "medium"
    },
    "cartographer_node.ERROR": {
        "category": "å®šä½å»ºå›¾",
        "description": "Cartographer SLAMæ—¥å¿—(ERRORçº§åˆ«)ï¼Œè®°å½•ä¸¥é‡é”™è¯¯",
        "keywords": ["cartographer", "slam", "error"],
        "problems": ["SLAMå´©æºƒ", "ä¸¥é‡å®šä½é”™è¯¯"],
        "importance": "high"
    },
    "carto_restart.log": {
        "category": "å®šä½å»ºå›¾",
        "description": "Cartographeré‡å¯æ—¥å¿—ï¼Œè®°å½•SLAMé‡å¯å’Œæ¢å¤",
        "keywords": ["restart", "carto", "switch", "lidar"],
        "problems": ["SLAMé¢‘ç¹é‡å¯", "å®šä½æ¢å¤å¤±è´¥"],
        "importance": "medium"
    },
    
    # ===== ä¼ æ„Ÿå™¨å±‚ =====
    "bluesea2_node.log": {
        "category": "ä¼ æ„Ÿå™¨",
        "description": "æ¿€å…‰é›·è¾¾æ—¥å¿—ï¼Œè®°å½•æ¿€å…‰é›·è¾¾è¿æ¥å’Œæ•°æ®çŠ¶æ€",
        "keywords": ["lidar", "laser", "scan", "uart", "connect"],
        "problems": ["é›·è¾¾æ–­è¿", "é›·è¾¾æ•°æ®å¼‚å¸¸", "æ‰«æå¤±è´¥"],
        "importance": "high"
    },
    "ascamera_rgbd_up.log": {
        "category": "ä¼ æ„Ÿå™¨",
        "description": "ä¸Šæ–¹RGBDç›¸æœºæ—¥å¿—ï¼Œè®°å½•æ·±åº¦ç›¸æœºçŠ¶æ€",
        "keywords": ["camera", "rgbd", "depth", "image"],
        "problems": ["ä¸Šç›¸æœºå¼‚å¸¸", "æ·±åº¦å›¾å¼‚å¸¸", "ç›¸æœºæ–­è¿"],
        "importance": "medium"
    },
    "ascamera_rgbd_down.log": {
        "category": "ä¼ æ„Ÿå™¨",
        "description": "ä¸‹æ–¹RGBDç›¸æœºæ—¥å¿—ï¼Œè®°å½•é¿éšœç›¸æœºçŠ¶æ€",
        "keywords": ["camera", "rgbd", "depth", "obstacle"],
        "problems": ["ä¸‹ç›¸æœºå¼‚å¸¸", "é¿éšœç›¸æœºæ•…éšœ"],
        "importance": "medium"
    },
    "camera_calibration.log": {
        "category": "ä¼ æ„Ÿå™¨",
        "description": "ç›¸æœºæ ‡å®šæ—¥å¿—ï¼Œè®°å½•ç›¸æœºå¤–å‚å’Œæ ‡å®šç»“æœ",
        "keywords": ["calibration", "tf", "transform", "camera"],
        "problems": ["æ ‡å®šå¼‚å¸¸", "ç›¸æœºä½å§¿é”™è¯¯"],
        "importance": "low"
    },
    "ydlidar_ros_driver.log": {
        "category": "ä¼ æ„Ÿå™¨",
        "description": "YDLidaræ¿€å…‰é›·è¾¾é©±åŠ¨æ—¥å¿—",
        "keywords": ["ydlidar", "lidar", "scan"],
        "problems": ["é›·è¾¾é©±åŠ¨é—®é¢˜"],
        "importance": "medium"
    },
    "virtual_bumper.log": {
        "category": "ä¼ æ„Ÿå™¨",
        "description": "è™šæ‹Ÿç¢°æ’å¸¦æ—¥å¿—ï¼Œè®°å½•è™šæ‹Ÿå®‰å…¨è¾¹ç•Œ",
        "keywords": ["bumper", "virtual", "safety", "collision"],
        "problems": ["è™šæ‹Ÿç¢°æ’å¼‚å¸¸", "å®‰å…¨åŒºåŸŸé—®é¢˜"],
        "importance": "medium"
    },
    
    # ===== ä»»åŠ¡å±‚ =====
    "auto_docking.log": {
        "category": "ä»»åŠ¡",
        "description": "è‡ªåŠ¨å›å……æ—¥å¿—ï¼Œè®°å½•å›å……æ¡©å¯¹æ¥è¿‡ç¨‹",
        "keywords": ["docking", "charge", "dock", "ultrasonic", "laser"],
        "problems": ["å›å……å¤±è´¥", "å¯¹æ¡©å¤±è´¥", "å……ç”µå¼‚å¸¸"],
        "importance": "high"
    },
    "ipa_room_exploration.log": {
        "category": "ä»»åŠ¡",
        "description": "æˆ¿é—´æ¢ç´¢æ—¥å¿—ï¼Œè®°å½•æ¸…æ‰«è·¯å¾„è§„åˆ’",
        "keywords": ["exploration", "room", "path", "boustrophedon", "coverage"],
        "problems": ["æ¸…æ‰«è·¯å¾„å¼‚å¸¸", "åŒºåŸŸè¦†ç›–ä¸å…¨"],
        "importance": "medium"
    },
    "ipa_room_segmentation.log": {
        "category": "ä»»åŠ¡",
        "description": "æˆ¿é—´åˆ†å‰²æ—¥å¿—ï¼Œè®°å½•åœ°å›¾åŒºåŸŸåˆ†å‰²",
        "keywords": ["segmentation", "room", "map", "morphological"],
        "problems": ["æˆ¿é—´åˆ†å‰²é”™è¯¯", "åŒºåŸŸè¯†åˆ«å¼‚å¸¸"],
        "importance": "low"
    },
    "elevator.log": {
        "category": "ä»»åŠ¡",
        "description": "ç”µæ¢¯æ§åˆ¶æ—¥å¿—ï¼Œè®°å½•è·¨æ¥¼å±‚å’Œç”µæ¢¯äº¤äº’",
        "keywords": ["elevator", "floor", "lift"],
        "problems": ["ç”µæ¢¯å¯¹æ¥å¤±è´¥", "è·¨æ¥¼å±‚å¼‚å¸¸"],
        "importance": "medium"
    },
    
    # ===== é€šä¿¡å±‚ =====
    "01_00_58_grpc.log": {
        "category": "é€šä¿¡",
        "description": "gRPCé€šä¿¡æ—¥å¿—ï¼Œè®°å½•å†…ç½‘é€šä¿¡å’ŒROS LANé€šä¿¡",
        "keywords": ["grpc", "network", "connect", "lan", "roslan"],
        "problems": ["ç½‘ç»œæ–­è¿", "gRPCé€šä¿¡å¤±è´¥", "å†…ç½‘å¼‚å¸¸"],
        "importance": "high"
    },
    "00_00_04_mqtt.txt": {
        "category": "é€šä¿¡",
        "description": "MQTTé€šä¿¡æ—¥å¿—ï¼Œè®°å½•äº‘ç«¯é€šä¿¡å’Œæ¶ˆæ¯æ”¶å‘",
        "keywords": ["mqtt", "cloud", "message", "connect", "ssl"],
        "problems": ["äº‘ç«¯æ–­è¿", "MQTTé€šä¿¡å¤±è´¥", "æ¶ˆæ¯ä¸¢å¤±"],
        "importance": "high"
    },
    
    # ===== ç³»ç»Ÿå±‚ =====
    "app_base.log": {
        "category": "ç³»ç»Ÿ",
        "description": "åº”ç”¨åŸºç¡€æ—¥å¿—ï¼Œè®°å½•ç‰ˆæœ¬ä¿¡æ¯å’Œç³»ç»Ÿé…ç½®",
        "keywords": ["version", "config", "app", "robot"],
        "problems": ["ç‰ˆæœ¬ä¸åŒ¹é…", "é…ç½®é”™è¯¯"],
        "importance": "low"
    },
    "ikitrobot_one.log": {
        "category": "ç³»ç»Ÿ",
        "description": "æœºå™¨äººä¸»èŠ‚ç‚¹æ—¥å¿—ï¼Œè®°å½•ROSç³»ç»Ÿå¯åŠ¨",
        "keywords": ["roslaunch", "node", "startup"],
        "problems": ["èŠ‚ç‚¹å¯åŠ¨å¤±è´¥", "ROSç³»ç»Ÿå¼‚å¸¸"],
        "importance": "medium"
    },
    "state_publish.log": {
        "category": "ç³»ç»Ÿ",
        "description": "çŠ¶æ€å‘å¸ƒæ—¥å¿—ï¼Œè®°å½•æœºå™¨äººçŠ¶æ€å¹¿æ’­",
        "keywords": ["state", "publish", "status"],
        "problems": ["çŠ¶æ€å‘å¸ƒå¼‚å¸¸"],
        "importance": "low"
    },
    "robot_demo2.log": {
        "category": "ç³»ç»Ÿ",
        "description": "æœºå™¨äººæ¼”ç¤ºå’Œä»»åŠ¡æ‰§è¡Œæ—¥å¿—",
        "keywords": ["demo", "task", "execute"],
        "problems": ["ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸"],
        "importance": "medium"
    },
    
    # ===== é€šç”¨æ—¥å¿— =====
    "00_00_00.txt": {
        "category": "é€šç”¨",
        "description": "é€šç”¨ç³»ç»Ÿæ—¥å¿—ï¼Œè®°å½•WiFiã€å•†æˆ·ä¿¡æ¯ç­‰",
        "keywords": ["wifi", "merchant", "task", "system"],
        "problems": ["WiFiæ–­è¿", "ç³»ç»Ÿå¼‚å¸¸"],
        "importance": "medium"
    },
    "00_00_04_can.txt": {
        "category": "é€šç”¨",
        "description": "CANæ€»çº¿æ—¥å¿—ï¼Œè®°å½•ç”µæ± å’Œæ¸…æ´æ¨¡å—çŠ¶æ€",
        "keywords": ["can", "battery", "clean", "water"],
        "problems": ["CANé€šä¿¡å¼‚å¸¸", "æ¸…æ´æ¨¡å—æ•…éšœ", "æ°´ç®±é—®é¢˜"],
        "importance": "medium"
    },
    "01_01_31_action.txt": {
        "category": "é€šç”¨",
        "description": "åŠ¨ä½œæ—¥å¿—ï¼Œè®°å½•å®šä½çŠ¶æ€å’Œå…¨å±€ä½å§¿",
        "keywords": ["action", "localization", "pose", "global"],
        "problems": ["å®šä½çŠ¶æ€å¼‚å¸¸", "ä½å§¿é”™è¯¯"],
        "importance": "medium"
    },
}

# é—®é¢˜ç±»å‹åˆ°æ—¥å¿—æ–‡ä»¶çš„æ˜ å°„
PROBLEM_LOG_MAPPING = {
    "å¯¼èˆª": ["navigation_move_base.log", "navigation_hsm_flex.log", "cartographer_node.INFO", "odometry_node.log"],
    "å®šä½": ["cartographer_node.INFO", "cartographer_node.WARNING", "cartographer_node.ERROR", "carto_restart.log", "01_01_31_action.txt"],
    "å»ºå›¾": ["cartographer_node.INFO", "cartographer_node.WARNING", "carto_restart.log"],
    "å……ç”µ": ["auto_docking.log", "ikitbot_driver.log", "00_00_04_can.txt"],
    "å›å……": ["auto_docking.log", "ikitbot_driver.log", "navigation_move_base.log"],
    "ç”µæ± ": ["ikitbot_driver.log", "00_00_04_can.txt"],
    "ç”µæœº": ["ikitbot_driver.log", "odometry_node.log"],
    "ä¼ æ„Ÿå™¨": ["ikitbot_driver.log", "bluesea2_node.log", "ascamera_rgbd_up.log", "ascamera_rgbd_down.log"],
    "é›·è¾¾": ["bluesea2_node.log", "cartographer_node.INFO", "carto_restart.log"],
    "ç›¸æœº": ["ascamera_rgbd_up.log", "ascamera_rgbd_down.log", "camera_calibration.log"],
    "ç¢°æ’": ["ikitbot_driver.log", "virtual_bumper.log"],
    "é¿éšœ": ["navigation_move_base.log", "virtual_bumper.log", "ascamera_rgbd_down.log"],
    "ç½‘ç»œ": ["01_00_58_grpc.log", "00_00_04_mqtt.txt", "00_00_00.txt"],
    "é€šä¿¡": ["01_00_58_grpc.log", "00_00_04_mqtt.txt"],
    "WiFi": ["00_00_00.txt", "00_00_04_mqtt.txt"],
    "æ¸…æ‰«": ["ipa_room_exploration.log", "ipa_room_segmentation.log", "robot_demo2.log"],
    "ä»»åŠ¡": ["robot_demo2.log", "ipa_room_exploration.log", "navigation_hsm_flex.log"],
    "ç”µæ¢¯": ["elevator.log", "navigation_hsm_flex.log"],
    "å¯åŠ¨": ["ikitrobot_one.log", "app_base.log"],
    "ç³»ç»Ÿ": ["app_base.log", "ikitrobot_one.log", "state_publish.log"],
}


class LogDiagnosticAgent:
    """æ™ºèƒ½æ—¥å¿—è¯Šæ–­Agent"""
    
    def __init__(self, log_directory: str = None, api_key: str = None, base_url: str = None):
        self.log_directory = log_directory or LOG_DIRECTORY
        self.api_key = api_key or DEEPSEEK_API_KEY
        self.base_url = base_url or DEEPSEEK_BASE_URL
        self.conversation_history = []
        self.analyzed_logs = {}  # ç¼“å­˜å·²åˆ†æçš„æ—¥å¿—å†…å®¹
        self.diagnosis_context = {}  # è¯Šæ–­ä¸Šä¸‹æ–‡
        
    def _call_llm(self, messages: List[Dict], max_tokens: int = None) -> str:
        """è°ƒç”¨LLM"""
        if not self.api_key or self.api_key == 'your-deepseek-api-key-here':
            return self._fallback_response(messages[-1].get('content', ''))
        
        try:
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.api_key}"
            }
            
            data = {
                "model": DEEPSEEK_MODEL,
                "messages": messages,
                "max_tokens": max_tokens or 2000,
                "temperature": 0.3  # ä½¿ç”¨è¾ƒä½æ¸©åº¦ä»¥è·å¾—æ›´ç¡®å®šçš„ç»“æœ
            }
            
            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers=headers,
                json=data,
                timeout=REQUEST_TIMEOUT
            )
            
            if response.status_code == 200:
                result = response.json()
                return result["choices"][0]["message"]["content"].strip()
            else:
                print(f"LLMè°ƒç”¨å¤±è´¥: {response.status_code}")
                return self._fallback_response(messages[-1].get('content', ''))
                
        except Exception as e:
            print(f"LLMè°ƒç”¨å¼‚å¸¸: {e}")
            return self._fallback_response(messages[-1].get('content', ''))
    
    def _fallback_response(self, query: str) -> str:
        """å¤‡ç”¨å“åº”"""
        return json.dumps({
            "action": "analyze",
            "relevant_logs": ["ikitbot_driver.log", "navigation_move_base.log"],
            "reasoning": "APIä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤æ—¥å¿—è¿›è¡Œåˆ†æ"
        })
    
    def _get_available_logs(self) -> List[str]:
        """è·å–å¯ç”¨çš„æ—¥å¿—æ–‡ä»¶åˆ—è¡¨"""
        logs = []
        if os.path.exists(self.log_directory):
            for f in os.listdir(self.log_directory):
                if f.endswith(('.log', '.txt', '.INFO', '.WARNING', '.ERROR')):
                    logs.append(f)
        return logs
    
    def get_log_knowledge(self) -> Dict[str, Any]:
        """è·å–æ—¥å¿—çŸ¥è¯†åº“ä¿¡æ¯ï¼ˆä¾›APIè°ƒç”¨ï¼‰"""
        return LOG_KNOWLEDGE_BASE
    
    def list_available_logs(self) -> List[Dict[str, Any]]:
        """åˆ—å‡ºå½“å‰æ—¥å¿—ç›®å½•ä¸­å¯ç”¨çš„æ—¥å¿—æ–‡ä»¶åŠå…¶ä¿¡æ¯"""
        available = []
        if not os.path.exists(self.log_directory):
            return available
        
        for filename in os.listdir(self.log_directory):
            if not filename.endswith(('.log', '.txt', '.INFO', '.WARNING', '.ERROR')):
                continue
            
            file_path = os.path.join(self.log_directory, filename)
            file_size = os.path.getsize(file_path)
            
            # æŸ¥æ‰¾çŸ¥è¯†åº“ä¸­çš„æè¿°
            description = "æœªçŸ¥æ—¥å¿—ç±»å‹"
            category = "æœªåˆ†ç±»"
            keywords = []
            
            for pattern, info in LOG_KNOWLEDGE_BASE.items():
                # ç²¾ç¡®åŒ¹é…æˆ–æ¨¡å¼åŒ¹é…
                if pattern == filename or pattern in filename:
                    description = info.get('description', 'æœªçŸ¥')
                    category = info.get('category', 'æœªåˆ†ç±»')
                    keywords = info.get('keywords', [])
                    break
            
            available.append({
                'name': filename,
                'path': file_path,
                'size': file_size,
                'size_readable': f"{file_size / 1024:.1f} KB" if file_size < 1024*1024 else f"{file_size / 1024 / 1024:.1f} MB",
                'category': category,
                'description': description,
                'keywords': keywords
            })
        
        # æŒ‰ç±»åˆ«æ’åº
        available.sort(key=lambda x: (x['category'], x['name']))
        return available
    
    def _read_log_content(self, log_file: str, max_lines: int = 500, 
                          time_filter: Optional[Tuple[datetime, datetime]] = None) -> str:
        """è¯»å–æ—¥å¿—å†…å®¹"""
        file_path = os.path.join(self.log_directory, log_file)
        if not os.path.exists(file_path):
            return f"[æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {log_file}]"
        
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                lines = f.readlines()
            
            # å¦‚æœæœ‰æ—¶é—´è¿‡æ»¤
            if time_filter:
                start_time, end_time = time_filter
                filtered_lines = []
                for line in lines:
                    ts = self._extract_timestamp(line)
                    if ts and start_time <= ts <= end_time:
                        filtered_lines.append(line)
                lines = filtered_lines
            
            # é™åˆ¶è¡Œæ•°
            if len(lines) > max_lines:
                # å–å‰åéƒ¨åˆ†ï¼Œä¸­é—´çœç•¥
                half = max_lines // 2
                lines = lines[:half] + [f"\n... [çœç•¥ {len(lines) - max_lines} è¡Œ] ...\n"] + lines[-half:]
            
            return ''.join(lines)
        except Exception as e:
            return f"[è¯»å–å¤±è´¥: {e}]"
    
    def _extract_timestamp(self, line: str) -> Optional[datetime]:
        """ä»æ—¥å¿—è¡Œæå–æ—¶é—´æˆ³"""
        patterns = [
            r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})',
            r'(\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2})',
        ]
        for p in patterns:
            m = re.search(p, line)
            if m:
                try:
                    return datetime.strptime(m.group(1).replace('T', ' '), '%Y-%m-%d %H:%M:%S')
                except:
                    continue
        return None
    
    def _build_knowledge_context(self) -> str:
        """æ„å»ºæ—¥å¿—çŸ¥è¯†åº“ä¸Šä¸‹æ–‡"""
        available_logs = self._get_available_logs()
        
        context = "## å¯ç”¨æ—¥å¿—æ–‡ä»¶åŠå…¶è¯´æ˜\n\n"
        
        # æŒ‰ç±»åˆ«ç»„ç»‡
        by_category = defaultdict(list)
        for log_file in available_logs:
            info = LOG_KNOWLEDGE_BASE.get(log_file, {})
            category = info.get('category', 'å…¶ä»–')
            by_category[category].append((log_file, info))
        
        for category, logs in sorted(by_category.items()):
            context += f"### {category}\n"
            for log_file, info in logs:
                desc = info.get('description', 'æœªçŸ¥ç”¨é€”')
                problems = ', '.join(info.get('problems', [])[:3])
                context += f"- **{log_file}**: {desc}\n"
                if problems:
                    context += f"  - ç›¸å…³é—®é¢˜: {problems}\n"
            context += "\n"
        
        return context
    
    def _build_agent_system_prompt(self) -> str:
        """æ„å»ºAgentç³»ç»Ÿæç¤º"""
        knowledge = self._build_knowledge_context()
        
        return f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æœºå™¨äººæ—¥å¿—è¯Šæ–­Agentã€‚ä½ çš„ä»»åŠ¡æ˜¯å¸®åŠ©FAEï¼ˆç°åœºåº”ç”¨å·¥ç¨‹å¸ˆï¼‰åˆ†ææœºå™¨äººé—®é¢˜ã€‚

{knowledge}

## ä½ çš„å·¥ä½œæµç¨‹

1. **ç†è§£é—®é¢˜**: ä»”ç»†åˆ†æFAEæè¿°çš„é—®é¢˜ï¼Œè¯†åˆ«å…³é”®ä¿¡æ¯ï¼ˆç—‡çŠ¶ã€æ—¶é—´ã€é¢‘ç‡ç­‰ï¼‰
2. **é€‰æ‹©æ—¥å¿—**: æ ¹æ®é—®é¢˜ç±»å‹ï¼Œé€‰æ‹©æœ€ç›¸å…³çš„æ—¥å¿—æ–‡ä»¶è¿›è¡Œåˆ†æ
3. **åˆ†ææ—¥å¿—**: ä»æ—¥å¿—ä¸­æ‰¾å‡ºå¼‚å¸¸å’Œå…³é”®ä¿¡æ¯
4. **å…³è”åˆ†æ**: è·¨å¤šä¸ªæ—¥å¿—è¿›è¡Œå…³è”åˆ†æï¼Œæ‰¾å‡ºæ ¹æœ¬åŸå› 
5. **ç»™å‡ºå»ºè®®**: æä¾›å…·ä½“çš„æ’æŸ¥æ­¥éª¤å’Œè§£å†³æ–¹æ¡ˆ

## å“åº”æ ¼å¼

ä½ éœ€è¦ä»¥JSONæ ¼å¼å“åº”ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š

```json
{{
    "action": "select_logs" | "analyze" | "need_more_info" | "conclude",
    "reasoning": "ä½ çš„æ¨ç†è¿‡ç¨‹",
    "relevant_logs": ["æ—¥å¿—æ–‡ä»¶1", "æ—¥å¿—æ–‡ä»¶2"],
    "time_range": {{"start": "YYYY-MM-DD HH:MM:SS", "end": "YYYY-MM-DD HH:MM:SS"}} | null,
    "questions": ["éœ€è¦FAEè¡¥å……çš„é—®é¢˜"] | null,
    "analysis": "åˆ†æç»“æœ" | null,
    "root_cause": "æ ¹æœ¬åŸå› " | null,
    "suggestions": ["å»ºè®®1", "å»ºè®®2"] | null
}}
```

## æ³¨æ„äº‹é¡¹

- ä¼˜å…ˆé€‰æ‹©ä¸é—®é¢˜æœ€ç›¸å…³çš„æ—¥å¿—ï¼Œé¿å…åˆ†æä¸ç›¸å…³çš„æ—¥å¿—
- æ³¨æ„æ—¥å¿—ä¹‹é—´çš„æ—¶é—´å…³è”
- å…³æ³¨ERRORã€WARNçº§åˆ«çš„æ—¥å¿—
- å¯»æ‰¾å¼‚å¸¸æ¨¡å¼å’Œé‡å¤å‡ºç°çš„é—®é¢˜
- ç»™å‡ºçš„å»ºè®®è¦å…·ä½“å¯æ‰§è¡Œ"""
    
    def diagnose(self, problem_description: str, issue_time: str = None, 
                 window_minutes: int = 10) -> Dict[str, Any]:
        """
        è¯Šæ–­å…¥å£
        
        Args:
            problem_description: FAEæè¿°çš„é—®é¢˜
            issue_time: é—®é¢˜å‘ç”Ÿæ—¶é—´ (YYYY-MM-DD HH:MM:SS)
            window_minutes: æ—¶é—´çª—å£ï¼ˆåˆ†é’Ÿï¼‰
        
        Returns:
            è¯Šæ–­ç»“æœ
        """
        print(f"\nğŸ¤– å¯åŠ¨æ—¥å¿—è¯Šæ–­Agent...")
        print(f"   é—®é¢˜æè¿°: {problem_description}")
        if issue_time:
            print(f"   é—®é¢˜æ—¶é—´: {issue_time}")
        
        # åˆå§‹åŒ–è¯Šæ–­ä¸Šä¸‹æ–‡
        self.diagnosis_context = {
            'problem': problem_description,
            'issue_time': issue_time,
            'window_minutes': window_minutes,
            'steps': [],
            'analyzed_logs': [],
            'findings': [],
        }
        
        # è®¡ç®—æ—¶é—´èŒƒå›´
        time_filter = None
        if issue_time:
            try:
                center_time = datetime.strptime(issue_time, "%Y-%m-%d %H:%M:%S")
                time_filter = (
                    center_time - timedelta(minutes=window_minutes),
                    center_time + timedelta(minutes=window_minutes)
                )
            except:
                pass
        
        # Step 1: è®©Agenté€‰æ‹©ç›¸å…³æ—¥å¿—
        step1_result = self._step_select_logs(problem_description)
        self.diagnosis_context['steps'].append(('select_logs', step1_result))
        
        if step1_result.get('action') == 'need_more_info':
            return {
                'status': 'need_more_info',
                'questions': step1_result.get('questions', []),
                'reasoning': step1_result.get('reasoning', '')
            }
        
        relevant_logs = step1_result.get('relevant_logs', [])
        
        # Step 2: è¯»å–å¹¶åˆ†æç›¸å…³æ—¥å¿—
        log_contents = {}
        for log_file in relevant_logs[:5]:  # æœ€å¤šåˆ†æ5ä¸ªæ—¥å¿—
            content = self._read_log_content(log_file, max_lines=300, time_filter=time_filter)
            log_contents[log_file] = content
            self.diagnosis_context['analyzed_logs'].append(log_file)
        
        # Step 3: è®©Agentåˆ†ææ—¥å¿—å†…å®¹
        step2_result = self._step_analyze_logs(problem_description, log_contents)
        self.diagnosis_context['steps'].append(('analyze', step2_result))
        
        # Step 4: ç”Ÿæˆæœ€ç»ˆè¯Šæ–­æŠ¥å‘Š
        final_result = self._step_conclude(problem_description, step1_result, step2_result)
        self.diagnosis_context['steps'].append(('conclude', final_result))
        
        return {
            'status': 'completed',
            'problem': problem_description,
            'issue_time': issue_time,
            'analyzed_logs': relevant_logs,
            'log_selection_reasoning': step1_result.get('reasoning', ''),
            'analysis': step2_result.get('analysis', ''),
            'root_cause': final_result.get('root_cause', ''),
            'suggestions': final_result.get('suggestions', []),
            'key_findings': final_result.get('key_findings', []),
            'confidence': final_result.get('confidence', 'medium'),
        }
    
    def _step_select_logs(self, problem: str) -> Dict:
        """Step 1: é€‰æ‹©ç›¸å…³æ—¥å¿—"""
        print("   ğŸ“‹ Step 1: åˆ†æé—®é¢˜ï¼Œé€‰æ‹©ç›¸å…³æ—¥å¿—...")
        
        messages = [
            {"role": "system", "content": self._build_agent_system_prompt()},
            {"role": "user", "content": f"""FAEåé¦ˆçš„é—®é¢˜ï¼š
{problem}

è¯·åˆ†æè¿™ä¸ªé—®é¢˜ï¼Œé€‰æ‹©éœ€è¦æŸ¥çœ‹çš„æ—¥å¿—æ–‡ä»¶ã€‚
æ³¨æ„ï¼šåªé€‰æ‹©ä¸é—®é¢˜æœ€ç›¸å…³çš„æ—¥å¿—ï¼ˆå»ºè®®3-5ä¸ªï¼‰ï¼Œä¸è¦é€‰æ‹©ä¸ç›¸å…³çš„æ—¥å¿—ã€‚

è¯·ä»¥JSONæ ¼å¼å“åº”ã€‚"""}
        ]
        
        response = self._call_llm(messages, max_tokens=1000)
        
        try:
            # å°è¯•æå–JSON
            json_match = re.search(r'\{[\s\S]*\}', response)
            if json_match:
                result = json.loads(json_match.group())
                print(f"   âœ… é€‰æ‹©äº† {len(result.get('relevant_logs', []))} ä¸ªæ—¥å¿—æ–‡ä»¶")
                return result
        except:
            pass
        
        # å¤‡ç”¨ï¼šä½¿ç”¨å…³é”®è¯åŒ¹é…
        return self._fallback_log_selection(problem)
    
    def _fallback_log_selection(self, problem: str) -> Dict:
        """å¤‡ç”¨æ—¥å¿—é€‰æ‹©é€»è¾‘"""
        selected_logs = set()
        problem_lower = problem.lower()
        
        # åŸºäºå…³é”®è¯åŒ¹é…
        for keyword, logs in PROBLEM_LOG_MAPPING.items():
            if keyword in problem_lower or keyword in problem:
                selected_logs.update(logs)
        
        # å¦‚æœæ²¡åŒ¹é…åˆ°ï¼Œè¿”å›é»˜è®¤æ—¥å¿—
        if not selected_logs:
            selected_logs = {"ikitbot_driver.log", "navigation_move_base.log", "cartographer_node.INFO"}
        
        available = set(self._get_available_logs())
        selected_logs = list(selected_logs & available)[:5]
        
        return {
            "action": "analyze",
            "relevant_logs": selected_logs,
            "reasoning": "åŸºäºå…³é”®è¯åŒ¹é…é€‰æ‹©æ—¥å¿—æ–‡ä»¶"
        }
    
    def _step_analyze_logs(self, problem: str, log_contents: Dict[str, str]) -> Dict:
        """Step 2: åˆ†ææ—¥å¿—å†…å®¹"""
        print("   ğŸ” Step 2: åˆ†ææ—¥å¿—å†…å®¹...")
        
        # æ„å»ºæ—¥å¿—å†…å®¹æ‘˜è¦
        logs_text = ""
        for log_file, content in log_contents.items():
            # æˆªå–å†…å®¹ï¼Œé¿å…è¶…å‡ºtokené™åˆ¶
            truncated = content[:8000] if len(content) > 8000 else content
            logs_text += f"\n\n### {log_file}\n```\n{truncated}\n```"
        
        messages = [
            {"role": "system", "content": self._build_agent_system_prompt()},
            {"role": "user", "content": f"""FAEåé¦ˆçš„é—®é¢˜ï¼š
{problem}

ä»¥ä¸‹æ˜¯ç›¸å…³æ—¥å¿—å†…å®¹ï¼š
{logs_text}

è¯·åˆ†æè¿™äº›æ—¥å¿—ï¼š
1. æ‰¾å‡ºä¸é—®é¢˜ç›¸å…³çš„å¼‚å¸¸å’Œé”™è¯¯
2. è¯†åˆ«å…³é”®çš„æ—¥å¿—è¡Œ
3. åˆ†æå¯èƒ½çš„åŸå› 
4. æ³¨æ„ä¸åŒæ—¥å¿—ä¹‹é—´çš„æ—¶é—´å…³è”

è¯·ä»¥JSONæ ¼å¼å“åº”ï¼ŒåŒ…å«è¯¦ç»†çš„analysiså­—æ®µã€‚"""}
        ]
        
        response = self._call_llm(messages, max_tokens=2000)
        
        try:
            json_match = re.search(r'\{[\s\S]*\}', response)
            if json_match:
                result = json.loads(json_match.group())
                print(f"   âœ… æ—¥å¿—åˆ†æå®Œæˆ")
                return result
        except:
            pass
        
        return {
            "action": "analyze",
            "analysis": response,
            "reasoning": "æ—¥å¿—åˆ†æç»“æœ"
        }
    
    def _step_conclude(self, problem: str, selection_result: Dict, analysis_result: Dict) -> Dict:
        """Step 3: ç”Ÿæˆç»“è®º"""
        print("   ğŸ“Š Step 3: ç”Ÿæˆè¯Šæ–­ç»“è®º...")
        
        messages = [
            {"role": "system", "content": """ä½ æ˜¯ä¸“ä¸šçš„æœºå™¨äººæ•…éšœè¯Šæ–­ä¸“å®¶ã€‚è¯·æ ¹æ®ä¹‹å‰çš„åˆ†æï¼Œç”Ÿæˆæœ€ç»ˆçš„è¯Šæ–­ç»“è®ºã€‚

è¾“å‡ºè¦æ±‚ï¼š
1. root_cause: æ˜ç¡®æŒ‡å‡ºæ ¹æœ¬åŸå› 
2. key_findings: åˆ—å‡ºå…³é”®å‘ç°ï¼ˆå…·ä½“çš„æ—¥å¿—è¯æ®ï¼‰
3. suggestions: ç»™å‡ºå…·ä½“å¯æ‰§è¡Œçš„è§£å†³å»ºè®®
4. confidence: è¯Šæ–­ç½®ä¿¡åº¦ (high/medium/low)

è¯·ä»¥JSONæ ¼å¼å“åº”ã€‚"""},
            {"role": "user", "content": f"""é—®é¢˜æè¿°: {problem}

æ—¥å¿—é€‰æ‹©ä¾æ®: {selection_result.get('reasoning', '')}

æ—¥å¿—åˆ†æç»“æœ: {analysis_result.get('analysis', '')}

è¯·ç”Ÿæˆæœ€ç»ˆè¯Šæ–­ç»“è®ºã€‚"""}
        ]
        
        response = self._call_llm(messages, max_tokens=1500)
        
        try:
            json_match = re.search(r'\{[\s\S]*\}', response)
            if json_match:
                result = json.loads(json_match.group())
                print(f"   âœ… è¯Šæ–­ç»“è®ºç”Ÿæˆå®Œæˆ")
                return result
        except:
            pass
        
        return {
            "root_cause": "éœ€è¦è¿›ä¸€æ­¥åˆ†æ",
            "key_findings": [],
            "suggestions": ["è¯·æä¾›æ›´å¤šä¿¡æ¯ä»¥ä¾¿æ·±å…¥åˆ†æ"],
            "confidence": "low"
        }
    
    def interactive_diagnose(self):
        """äº¤äº’å¼è¯Šæ–­æ¨¡å¼"""
        print("\n" + "="*60)
        print("ğŸ¤– æœºå™¨äººæ™ºèƒ½æ—¥å¿—è¯Šæ–­ç³»ç»Ÿ")
        print("="*60)
        print("è¾“å…¥é—®é¢˜æè¿°å¼€å§‹è¯Šæ–­ï¼Œè¾“å…¥ 'quit' é€€å‡º\n")
        
        while True:
            problem = input("ğŸ“ è¯·æè¿°é—®é¢˜: ").strip()
            if problem.lower() == 'quit':
                print("å†è§ï¼")
                break
            
            if not problem:
                continue
            
            # è¯¢é—®æ—¶é—´
            issue_time = input("â° é—®é¢˜å‘ç”Ÿæ—¶é—´ (YYYY-MM-DD HH:MM:SSï¼Œå¯é€‰): ").strip()
            if not issue_time:
                issue_time = None
            
            # æ‰§è¡Œè¯Šæ–­
            result = self.diagnose(problem, issue_time)
            
            # è¾“å‡ºç»“æœ
            print("\n" + "-"*60)
            print("ğŸ“‹ è¯Šæ–­ç»“æœ")
            print("-"*60)
            
            if result.get('status') == 'need_more_info':
                print("éœ€è¦è¡¥å……ä¿¡æ¯:")
                for q in result.get('questions', []):
                    print(f"  â“ {q}")
            else:
                print(f"\nğŸ” åˆ†æçš„æ—¥å¿—: {', '.join(result.get('analyzed_logs', []))}")
                print(f"\nğŸ“ é€‰æ‹©ä¾æ®: {result.get('log_selection_reasoning', '')}")
                print(f"\nğŸ”¬ åˆ†æç»“æœ:\n{result.get('analysis', '')}")
                print(f"\nğŸ¯ æ ¹æœ¬åŸå› : {result.get('root_cause', '')}")
                print(f"\nğŸ’¡ å»ºè®®:")
                for s in result.get('suggestions', []):
                    print(f"  â€¢ {s}")
                print(f"\nğŸ“Š ç½®ä¿¡åº¦: {result.get('confidence', '')}")
            
            print("\n" + "="*60 + "\n")


def create_agent_api_handler(log_directory: str = None):
    """åˆ›å»ºAgent APIå¤„ç†å‡½æ•°ï¼ˆä¾›Flaskä½¿ç”¨ï¼‰"""
    agent = LogDiagnosticAgent(log_directory=log_directory)
    
    def handle_diagnose(problem: str, issue_time: str = None, window: int = 10) -> Dict:
        return agent.diagnose(problem, issue_time, window)
    
    return handle_diagnose


if __name__ == "__main__":
    # æµ‹è¯•
    agent = LogDiagnosticAgent()
    agent.interactive_diagnose()
