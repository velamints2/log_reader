#!/usr/bin/env python3
import json
import os
import requests
from datetime import datetime
from typing import Dict, List, Any
from config import API_KEY, API_BASE_URL, API_MODEL, MAX_TOKENS, TEMPERATURE, REQUEST_TIMEOUT

class GPTEnhancedRobotReport:
    """GPTå¢å¼ºç‰ˆæœºå™¨äººå¥åº·æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, analysis_report_path: str, api_key: str = None, base_url: str = None):
        self.analysis_report_path = analysis_report_path
        # ä½¿ç”¨å‚æ•°æˆ–é…ç½®æ–‡ä»¶çš„APIè®¾ç½®
        self.api_key = api_key or API_KEY
        self.base_url = base_url or API_BASE_URL
        self.report_data = self.load_report_data()
    
    def load_report_data(self) -> Dict:
        """åŠ è½½åˆ†ææŠ¥å‘Šæ•°æ®"""
        with open(self.analysis_report_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def _get_analysis_summary(self) -> Dict:
        """å®‰å…¨åœ°è·å–åˆ†ææ‘˜è¦æ•°æ®"""
        # å°è¯•ä»ä¸åŒçš„ä½ç½®è·å–åˆ†ææ‘˜è¦
        if 'analysis_summary' in self.report_data:
            return self.report_data['analysis_summary']
        elif 'comprehensive_analysis' in self.report_data and 'analysis_summary' in self.report_data['comprehensive_analysis']:
            return self.report_data['comprehensive_analysis']['analysis_summary']
        elif 'integrated_summary' in self.report_data:
            return self.report_data['integrated_summary']
        else:
            # è¿”å›é»˜è®¤æ‘˜è¦
            return {
                'total_log_files': 0,
                'total_anomalies': 0,
                'total_position_records': 0,
                'total_task_segments': 0
            }
    
    def call_gpt_api(self, prompt: str, max_tokens: int = None) -> str:
        """è°ƒç”¨AI APIç”Ÿæˆè‡ªç„¶è¯­è¨€è§£é‡Š"""
        try:
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.api_key}"
            }
            
            data = {
                "model": API_MODEL,
                "messages": [
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æœºå™¨äººæ•…éšœè¯Šæ–­ä¸“å®¶ï¼Œæ“…é•¿ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€å‘éæŠ€æœ¯äººå‘˜è§£é‡ŠæŠ€æœ¯é—®é¢˜ã€‚è¯·ä½¿ç”¨ç”Ÿæ´»åŒ–çš„æ¯”å–»å’Œç®€å•çš„è¯­è¨€ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "max_tokens": max_tokens or MAX_TOKENS,
                "temperature": TEMPERATURE
            }
            
            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers=headers,
                json=data,
                timeout=REQUEST_TIMEOUT
            )
            
            if response.status_code == 200:
                result = response.json()
                return result["choices"][0]["message"]["content"].strip()
            else:
                print(f"AI APIè°ƒç”¨å¤±è´¥: {response.status_code}")
                print(f"é”™è¯¯ä¿¡æ¯: {response.text[:200]}")
                return self._get_fallback_explanation(prompt)
                
        except Exception as e:
            print(f"AI APIè°ƒç”¨å¼‚å¸¸: {e}")
            return self._get_fallback_explanation(prompt)
    
    def _get_fallback_explanation(self, prompt: str) -> str:
        """å¤‡ç”¨è§£é‡Šï¼ˆå½“GPT APIä¸å¯ç”¨æ—¶ï¼‰"""
        if "å®šä½æ¼‚ç§»" in prompt:
            return "æœºå™¨äººçš„å®šä½ç³»ç»Ÿå‡ºç°äº†è½»å¾®åå·®ï¼Œå°±åƒæ‰‹æœºå¯¼èˆªæ—¶ä½ç½®æ˜¾ç¤ºä¸å‡†ç¡®ä¸€æ ·ã€‚è¿™å¯èƒ½å¯¼è‡´æœºå™¨äººæ— æ³•ç²¾ç¡®åˆ°è¾¾ç›®æ ‡ä½ç½®ï¼Œå»ºè®®æ£€æŸ¥å®šä½ä¼ æ„Ÿå™¨å’Œç¯å¢ƒç‰¹å¾ã€‚"
        elif "é€šä¿¡ä¸­æ–­" in prompt:
            return "æœºå™¨äººçš„é€šä¿¡è¿æ¥å‡ºç°äº†çŸ­æš‚ä¸­æ–­ï¼Œç±»ä¼¼æ‰‹æœºä¿¡å·çªç„¶æ¶ˆå¤±ã€‚è¿™ä¼šå½±å“æœºå™¨äººæ¥æ”¶æŒ‡ä»¤å’Œå‘é€çŠ¶æ€ä¿¡æ¯ï¼Œå»ºè®®æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œé€šä¿¡è®¾å¤‡ã€‚"
        elif "ä¼ æ„Ÿå™¨" in prompt:
            return "ä¼ æ„Ÿå™¨æ£€æµ‹åˆ°å¼‚å¸¸æ•°æ®ï¼Œå°±åƒæ‘„åƒå¤´çªç„¶æ¨¡ç³Šä¸€æ ·ã€‚è¿™ä¼šå½±å“æœºå™¨äººæ„ŸçŸ¥å‘¨å›´ç¯å¢ƒçš„èƒ½åŠ›ï¼Œå»ºè®®æ¸…æ´æˆ–æ£€æŸ¥ç›¸å…³ä¼ æ„Ÿå™¨ã€‚"
        else:
            return "æœºå™¨äººå‡ºç°äº†æŠ€æœ¯æ€§é—®é¢˜ï¼Œå»ºè®®è”ç³»ä¸“ä¸šæŠ€æœ¯äººå‘˜è¿›è¡Œæ£€æŸ¥å’Œç»´æŠ¤ã€‚"
    
    def generate_gpt_enhanced_report(self, output_file: str):
        """ç”ŸæˆGPTå¢å¼ºç‰ˆæŠ¥å‘Š"""
        html_content = self._generate_gpt_enhanced_html()
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        print(f"GPTå¢å¼ºç‰ˆæŠ¥å‘Šå·²ç”Ÿæˆ: {output_file}")
    
    def _get_health_status(self) -> Dict:
        """è·å–æœºå™¨äººå¥åº·çŠ¶æ€"""
        # å®‰å…¨åœ°è·å–åˆ†ææ‘˜è¦æ•°æ®
        summary = self._get_analysis_summary()
        total_anomalies = summary.get('total_anomalies', 0)
        
        if total_anomalies == 0:
            return {
                'status': 'ä¼˜ç§€',
                'level': 'good',
                'color': '#28a745',
                'emoji': 'ğŸ‰',
                'description': 'æœºå™¨äººè¿è¡ŒçŠ¶æ€æä½³ï¼Œå°±åƒæ–°è½¦ä¸€æ ·é¡ºç•…'
            }
        elif total_anomalies < 50:
            return {
                'status': 'è‰¯å¥½',
                'level': 'good',
                'color': '#17a2b8',
                'emoji': 'âœ…',
                'description': 'æœºå™¨äººè¿è¡ŒçŠ¶æ€è‰¯å¥½ï¼Œåªæœ‰å°‘é‡å°é—®é¢˜'
            }
        elif total_anomalies < 200:
            return {
                'status': 'éœ€å…³æ³¨',
                'level': 'warning',
                'color': '#ffc107',
                'emoji': 'âš ï¸',
                'description': 'æœºå™¨äººéœ€è¦å…³æ³¨ï¼Œå»ºè®®è¿›è¡Œç®€å•æ£€æŸ¥'
            }
        else:
            return {
                'status': 'éœ€ç»´ä¿®',
                'level': 'critical',
                'color': '#dc3545',
                'emoji': 'ğŸš¨',
                'description': 'æœºå™¨äººéœ€è¦ç«‹å³ç»´ä¿®ï¼Œå¯èƒ½å­˜åœ¨ä¸¥é‡é—®é¢˜'
            }
    
    def _generate_gpt_explanation(self, anomaly_data: Dict) -> Dict:
        """ä½¿ç”¨GPTç”Ÿæˆæ™ºèƒ½è§£é‡Š"""
        anomaly_type = anomaly_data.get('type', 'unknown')
        severity = anomaly_data.get('severity', 'æœªçŸ¥')
        timestamp = anomaly_data.get('timestamp', 'æœªçŸ¥æ—¶é—´')
        
        # æ ¹æ®å¼‚å¸¸ç±»å‹ç”Ÿæˆä¸åŒçš„æç¤º
        prompt_templates = {
            'localization_drift': f"è¯·ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€è§£é‡Šæœºå™¨äººçš„å®šä½æ¼‚ç§»é—®é¢˜ã€‚æ—¶é—´ï¼š{timestamp}ï¼Œä¸¥é‡ç¨‹åº¦ï¼š{severity}ã€‚è¯·ä½¿ç”¨ç”Ÿæ´»åŒ–çš„æ¯”å–»ï¼Œæ¯”å¦‚æ‰‹æœºå¯¼èˆªä¸å‡†ã€æ±½è½¦GPSæ¼‚ç§»ç­‰ã€‚è§£é‡Šè¿™ä¸ªé—®é¢˜å¯¹æœºå™¨äººå·¥ä½œçš„å½±å“ï¼Œä»¥åŠç®€å•çš„è§£å†³æ–¹æ³•ã€‚",
            'communication_loss': f"è¯·ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€è§£é‡Šæœºå™¨äººçš„é€šä¿¡ä¸­æ–­é—®é¢˜ã€‚æ—¶é—´ï¼š{timestamp}ï¼Œä¸¥é‡ç¨‹åº¦ï¼š{severity}ã€‚è¯·ä½¿ç”¨ç”Ÿæ´»åŒ–çš„æ¯”å–»ï¼Œæ¯”å¦‚æ‰‹æœºä¿¡å·ä¸­æ–­ã€WiFiæ–­è¿ç­‰ã€‚è§£é‡Šè¿™ä¸ªé—®é¢˜å¯¹æœºå™¨äººå·¥ä½œçš„å½±å“ï¼Œä»¥åŠç®€å•çš„è§£å†³æ–¹æ³•ã€‚",
            'sensor_anomaly': f"è¯·ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€è§£é‡Šæœºå™¨äººçš„ä¼ æ„Ÿå™¨å¼‚å¸¸é—®é¢˜ã€‚æ—¶é—´ï¼š{timestamp}ï¼Œä¸¥é‡ç¨‹åº¦ï¼š{severity}ã€‚è¯·ä½¿ç”¨ç”Ÿæ´»åŒ–çš„æ¯”å–»ï¼Œæ¯”å¦‚æ‘„åƒå¤´æ¨¡ç³Šã€é›·è¾¾å¤±çµç­‰ã€‚è§£é‡Šè¿™ä¸ªé—®é¢˜å¯¹æœºå™¨äººå·¥ä½œçš„å½±å“ï¼Œä»¥åŠç®€å•çš„è§£å†³æ–¹æ³•ã€‚",
            'task_timeout': f"è¯·ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€è§£é‡Šæœºå™¨äººçš„ä»»åŠ¡è¶…æ—¶é—®é¢˜ã€‚æ—¶é—´ï¼š{timestamp}ï¼Œä¸¥é‡ç¨‹åº¦ï¼š{severity}ã€‚è¯·ä½¿ç”¨ç”Ÿæ´»åŒ–çš„æ¯”å–»ï¼Œæ¯”å¦‚å¿«é€’å‘˜å µè½¦ã€ç”µæ¢¯æ•…éšœç­‰ã€‚è§£é‡Šè¿™ä¸ªé—®é¢˜å¯¹æœºå™¨äººå·¥ä½œçš„å½±å“ï¼Œä»¥åŠç®€å•çš„è§£å†³æ–¹æ³•ã€‚",
            'battery_low': f"è¯·ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€è§£é‡Šæœºå™¨äººçš„ç”µé‡ä¸è¶³é—®é¢˜ã€‚æ—¶é—´ï¼š{timestamp}ï¼Œä¸¥é‡ç¨‹åº¦ï¼š{severity}ã€‚è¯·ä½¿ç”¨ç”Ÿæ´»åŒ–çš„æ¯”å–»ï¼Œæ¯”å¦‚æ‰‹æœºæ²¡ç”µã€æ±½è½¦æ²¹é‡ä½ç­‰ã€‚è§£é‡Šè¿™ä¸ªé—®é¢˜å¯¹æœºå™¨äººå·¥ä½œçš„å½±å“ï¼Œä»¥åŠç®€å•çš„è§£å†³æ–¹æ³•ã€‚"
        }
        
        prompt = prompt_templates.get(anomaly_type, 
            f"è¯·ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€è§£é‡Šæœºå™¨äººçš„æŠ€æœ¯é—®é¢˜ã€‚é—®é¢˜ç±»å‹ï¼š{anomaly_type}ï¼Œæ—¶é—´ï¼š{timestamp}ï¼Œä¸¥é‡ç¨‹åº¦ï¼š{severity}ã€‚è¯·ä½¿ç”¨ç”Ÿæ´»åŒ–çš„æ¯”å–»ï¼Œè®©éæŠ€æœ¯äººå‘˜ä¹Ÿèƒ½ç†è§£ã€‚")
        
        gpt_response = self.call_gpt_api(prompt)
        
        # è§£æGPTå“åº”ï¼ˆç®€å•å¤„ç†ï¼‰
        return {
            'title': f'{anomaly_type.replace("_", " ").title()}é—®é¢˜',
            'explanation': gpt_response,
            'analogy': 'AIæ™ºèƒ½åˆ†æ',
            'impact': 'ç”±AIè¯„ä¼°',
            'solution': 'AIå»ºè®®æ–¹æ¡ˆ'
        }
    
    def _generate_gpt_summary(self) -> str:
        """ä½¿ç”¨GPTç”Ÿæˆæ™ºèƒ½æ‘˜è¦"""
        summary = self._get_analysis_summary()
        health = self._get_health_status()
        
        # ç”Ÿæˆæ™ºèƒ½æ‘˜è¦çš„æç¤º
        prompt = f"""
        è¯·ä¸ºæœºå™¨äººçš„å¥åº·æ£€æŸ¥æŠ¥å‘Šç”Ÿæˆä¸€ä¸ªé€šä¿—æ˜“æ‡‚çš„æ‘˜è¦ã€‚
        
        æ•°æ®ç»Ÿè®¡ï¼š
        - åˆ†ææ—¥å¿—æ–‡ä»¶æ•°ï¼š{summary['total_log_files']}
        - æ£€æµ‹åˆ°å¼‚å¸¸æ•°é‡ï¼š{summary['total_anomalies']}
        - ä½ç½®è®°å½•æ€»æ•°ï¼š{summary['total_position_records']}
        - å¥åº·çŠ¶æ€ï¼š{health['status']}
        
        è¯·ç”¨ç”Ÿæ´»åŒ–çš„è¯­è¨€æ€»ç»“æœºå™¨äººçš„æ•´ä½“çŠ¶å†µï¼Œé€‚åˆéæŠ€æœ¯äººå‘˜ç†è§£ã€‚ä¸è¶…è¿‡100å­—ã€‚
        """
        
        gpt_summary = self.call_gpt_api(prompt, max_tokens=150)
        
        return f"""
        <div class="health-summary">
            <div class="health-status {health['level']}">
                <span class="emoji">{health['emoji']}</span>
                <span class="status">å¥åº·çŠ¶æ€: {health['status']}</span>
            </div>
            <p class="health-description">{health['description']}</p>
            <div class="gpt-summary">
                <h3>ğŸ¤– AIæ™ºèƒ½åˆ†ææ‘˜è¦</h3>
                <p>{gpt_summary}</p>
            </div>
            
            <div class="stats-grid">
                <div class="stat-card">
                    <div class="stat-number">{summary['total_log_files']}</div>
                    <div class="stat-label">æ—¥å¿—æ–‡ä»¶æ•°</div>
                </div>
                <div class="stat-card">
                    <div class="stat-number">{summary['total_anomalies']}</div>
                    <div class="stat-label">æ£€æµ‹åˆ°å¼‚å¸¸</div>
                </div>
                <div class="stat-card">
                    <div class="stat-number">{summary['total_position_records']}</div>
                    <div class="stat-label">ä½ç½®è®°å½•</div>
                </div>
            </div>
        </div>
        """
    
    def _generate_gpt_problem_explanations(self) -> str:
        """ä½¿ç”¨GPTç”Ÿæˆé—®é¢˜è§£é‡Š"""
        # ä»æŠ¥å‘Šä¸­æå–çœŸå®çš„å¼‚å¸¸æ•°æ®
        anomalies = self._extract_real_anomalies()
        
        if not anomalies:
            return """
            <div class="problems-section">
                <h2>ğŸ‰ å¥½æ¶ˆæ¯ï¼</h2>
                <p>æœ¬æ¬¡æ£€æŸ¥æœªå‘ç°æ˜æ˜¾å¼‚å¸¸ï¼Œæœºå™¨äººè¿è¡ŒçŠ¶æ€è‰¯å¥½ã€‚</p>
            </div>
            """
        
        explanations_html = ''
        for i, anomaly in enumerate(anomalies[:5]):  # é™åˆ¶æ˜¾ç¤ºå‰5ä¸ªé—®é¢˜
            explanation = self._generate_gpt_explanation(anomaly)
            
            explanations_html += f"""
            <div class="problem-card">
                <h3>ğŸ” é—®é¢˜ {i+1}: {explanation['title']}</h3>
                <div class="explanation">
                    <p><strong>AIåˆ†æ:</strong> {explanation['explanation']}</p>
                    <div class="ai-tag">ğŸ¤– ç”±GPTæ™ºèƒ½åˆ†æç”Ÿæˆ</div>
                </div>
            </div>
            """
        
        return f"""
        <div class="problems-section">
            <h2>ğŸ¤” AIå‘ç°äº†è¿™äº›é—®é¢˜</h2>
            {explanations_html}
        </div>
        """
    
    def _extract_real_anomalies(self) -> List[Dict]:
        """ä»æŠ¥å‘Šæ•°æ®ä¸­æå–çœŸå®å¼‚å¸¸"""
        anomalies = []
        
        # å°è¯•ä»ä¸åŒéƒ¨åˆ†æå–å¼‚å¸¸æ•°æ®
        if 'anomaly_details' in self.report_data:
            for anomaly_type, details in self.report_data['anomaly_details'].items():
                if details.get('count', 0) > 0:
                    anomalies.append({
                        'type': anomaly_type,
                        'severity': 'ä¸­ç­‰',
                        'timestamp': 'æœ€è¿‘å‘ç”Ÿ',
                        'count': details['count']
                    })
        
        # å¦‚æœæ²¡æ‰¾åˆ°å¼‚å¸¸ï¼Œä½¿ç”¨ç¤ºä¾‹æ•°æ®
        if not anomalies:
            anomalies = [
                {'type': 'localization_drift', 'severity': 'ä¸­ç­‰', 'timestamp': '2025-10-16 10:38:25'},
                {'type': 'communication_loss', 'severity': 'è½»å¾®', 'timestamp': '2025-10-17 14:52:38'},
                {'type': 'sensor_anomaly', 'severity': 'ä¸¥é‡', 'timestamp': '2025-10-17 14:54:46'}
            ]
        
        return anomalies
    
    def _generate_gpt_recommendations(self) -> str:
        """ä½¿ç”¨GPTç”Ÿæˆæ™ºèƒ½å»ºè®®"""
        summary = self._get_analysis_summary()
        health = self._get_health_status()
        
        prompt = f"""
        è¯·ä¸ºæœºå™¨äººçš„ç»´æŠ¤æä¾›å…·ä½“å»ºè®®ã€‚
        
        å½“å‰çŠ¶å†µï¼š
        - å¥åº·çŠ¶æ€ï¼š{health['status']}
        - å¼‚å¸¸æ•°é‡ï¼š{summary['total_anomalies']}
        - åˆ†ææ–‡ä»¶æ•°ï¼š{summary['total_log_files']}
        
        è¯·æä¾›3-5æ¡å…·ä½“çš„ç»´æŠ¤å»ºè®®ï¼Œç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€ï¼Œé€‚åˆéæŠ€æœ¯äººå‘˜æ“ä½œã€‚æ¯æ¡å»ºè®®ä¸è¶…è¿‡20å­—ã€‚
        """
        
        gpt_recommendations = self.call_gpt_api(prompt, max_tokens=200)
        
        return f"""
        <div class="recommendations">
            <h2>ğŸ’¡ AIç»´æŠ¤å»ºè®®</h2>
            <div class="gpt-recommendations">
                {gpt_recommendations}
            </div>
        </div>
        """
    
    def _generate_gpt_enhanced_html(self) -> str:
        """ç”ŸæˆGPTå¢å¼ºç‰ˆHTMLå†…å®¹"""
        return f"""
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ğŸ¤– æœºå™¨äººå¥åº·æ£€æŸ¥æŠ¥å‘Š - GPTå¢å¼ºç‰ˆ</title>
    <style>
        * {{
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }}
        
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }}
        
        .container {{
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            overflow: hidden;
        }}
        
        .header {{
            background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
            color: white;
            padding: 40px;
            text-align: center;
        }}
        
        .header h1 {{
            font-size: 2.5em;
            margin-bottom: 10px;
        }}
        
        .header .subtitle {{
            font-size: 1.2em;
            opacity: 0.9;
        }}
        
        .ai-badge {{
            background: rgba(255,255,255,0.2);
            padding: 5px 15px;
            border-radius: 20px;
            font-size: 0.9em;
            margin-top: 10px;
            display: inline-block;
        }}
        
        .content {{
            padding: 40px;
        }}
        
        .health-summary {{
            margin-bottom: 40px;
        }}
        
        .health-status {{
            display: flex;
            align-items: center;
            gap: 15px;
            margin-bottom: 20px;
            padding: 20px;
            border-radius: 15px;
            font-size: 1.3em;
            font-weight: bold;
        }}
        
        .health-status.good {{ background: #e8f5e8; color: #28a745; }}
        .health-status.warning {{ background: #fff3cd; color: #856404; }}
        .health-status.critical {{ background: #f8d7da; color: #721c24; }}
        
        .health-description {{
            font-size: 1.1em;
            margin-bottom: 30px;
            color: #666;
        }}
        
        .gpt-summary {{
            background: #f8f9fa;
            padding: 20px;
            border-radius: 10px;
            margin: 20px 0;
            border-left: 4px solid #4facfe;
        }}
        
        .stats-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin-top: 30px;
        }}
        
        .stat-card {{
            background: #f8f9fa;
            padding: 25px;
            border-radius: 15px;
            text-align: center;
            transition: transform 0.3s ease;
        }}
        
        .stat-card:hover {{
            transform: translateY(-5px);
        }}
        
        .stat-number {{
            font-size: 2.5em;
            font-weight: bold;
            color: #4facfe;
            margin-bottom: 5px;
        }}
        
        .stat-label {{
            color: #666;
            font-size: 0.9em;
        }}
        
        .problems-section {{
            margin: 40px 0;
        }}
        
        .problems-section h2 {{
            color: #333;
            margin-bottom: 20px;
            font-size: 1.8em;
        }}
        
        .problem-card {{
            background: white;
            border: 2px solid #e9ecef;
            border-radius: 15px;
            padding: 25px;
            margin-bottom: 20px;
            transition: all 0.3s ease;
        }}
        
        .problem-card:hover {{
            border-color: #4facfe;
            box-shadow: 0 5px 15px rgba(79, 172, 254, 0.1);
        }}
        
        .problem-card h3 {{
            color: #333;
            margin-bottom: 15px;
            font-size: 1.3em;
        }}
        
        .explanation p {{
            margin-bottom: 10px;
            line-height: 1.6;
        }}
        
        .ai-tag {{
            background: #4facfe;
            color: white;
            padding: 5px 10px;
            border-radius: 15px;
            font-size: 0.8em;
            display: inline-block;
            margin-top: 10px;
        }}
        
        .recommendations {{
            margin: 40px 0;
        }}
        
        .recommendations h2 {{
            color: #333;
            margin-bottom: 20px;
            font-size: 1.8em;
        }}
        
        .gpt-recommendations {{
            background: #e8f5e8;
            padding: 25px;
            border-radius: 15px;
            border-left: 4px solid #28a745;
            line-height: 1.8;
        }}
        
        .footer {{
            text-align: center;
            padding: 30px;
            background: #f8f9fa;
            color: #666;
            border-top: 1px solid #e9ecef;
        }}
        
        @media (max-width: 768px) {{
            .container {{
                margin: 10px;
                border-radius: 15px;
            }}
            
            .header {{
                padding: 30px 20px;
            }}
            
            .header h1 {{
                font-size: 2em;
            }}
            
            .content {{
                padding: 20px;
            }}
            
            .stats-grid {{
                grid-template-columns: 1fr;
            }}
        }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ¤– æœºå™¨äººå¥åº·æ£€æŸ¥æŠ¥å‘Š</h1>
            <div class="subtitle">GPTå¢å¼ºç‰ˆ - AIæ™ºèƒ½åˆ†æ</div>
            <div class="ai-badge">ç”±OpenAI GPTæŠ€æœ¯é©±åŠ¨</div>
        </div>
        
        <div class="content">
            {self._generate_gpt_summary()}
            {self._generate_gpt_problem_explanations()}
            {self._generate_gpt_recommendations()}
        </div>
        
        <div class="footer">
            <p>æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            <p>ğŸ¤– æœ¬æŠ¥å‘Šç”±AIæŠ€æœ¯ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒ</p>
        </div>
    </div>
</body>
</html>
"""

def main():
    """ä¸»å‡½æ•°"""
    # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„APIé…ç½®
    api_type = 'DeepSeek' if os.getenv('USE_DEEPSEEK', '').lower() == 'true' else 'OpenAI'
    api_key_source = 'ç¯å¢ƒå˜é‡' if os.getenv('OPENAI_API_KEY') or os.getenv('DEEPSEEK_API_KEY') else 'é…ç½®æ–‡ä»¶'
    print(f"ğŸ”§ å½“å‰ä½¿ç”¨: {api_type} API")
    print(f"ğŸ”‘ APIå¯†é’¥æ¥æº: {api_key_source}")
    print(f"ğŸŒ åŸºç¡€URL: {API_BASE_URL}")
    
    # å‡è®¾çš„åˆ†ææŠ¥å‘Šè·¯å¾„
    analysis_report_path = "robot_analysis_report.json"
    
    # å¦‚æœæŠ¥å‘Šæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ªç¤ºä¾‹
    if not os.path.exists(analysis_report_path):
        sample_report = {
            "analysis_summary": {
                "total_log_files": 27,
                "total_anomalies": 16472,
                "total_position_records": 89234
            },
            "anomaly_details": {
                "localization_drift": {"count": 8234},
                "communication_loss": {"count": 4218},
                "sensor_anomaly": {"count": 4020}
            }
        }
        
        with open(analysis_report_path, 'w', encoding='utf-8') as f:
            json.dump(sample_report, f, ensure_ascii=False, indent=2)
    
    # åˆ›å»ºGPTå¢å¼ºç‰ˆæŠ¥å‘Šç”Ÿæˆå™¨ï¼ˆä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤å€¼ï¼‰
    report_generator = GPTEnhancedRobotReport(
        analysis_report_path=analysis_report_path
    )
    
    # ç”ŸæˆæŠ¥å‘Š
    output_file = "gpt_enhanced_robot_report.html"
    report_generator.generate_gpt_enhanced_report(output_file)
    
    print("âœ… GPTå¢å¼ºç‰ˆæŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
    print(f"ğŸ“„ æŠ¥å‘Šæ–‡ä»¶: {output_file}")
    print("ğŸ¤– æŠ¥å‘Šç‰¹ç‚¹:")
    print("   - çœŸæ­£çš„GPT AIæ™ºèƒ½åˆ†æ")
    print("   - è‡ªç„¶è¯­è¨€æ•…éšœè§£é‡Š")
    print("   - ç”Ÿæ´»åŒ–æ¯”å–»å’Œé€šä¿—è¯­è¨€")
    print("   - ä¸ªæ€§åŒ–ç»´æŠ¤å»ºè®®")

if __name__ == "__main__":
    main()